<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  
  <title>Real or Not? NLP with Disaster Tweets を解く | gojiteji&#39;s Blog</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <meta name="description" content="前回、NNで翻訳を作ってみたのですが、モデルの評価等をすっ飛ばしてきました。そこで、今回はkaggleで現在開いているNLPの問題を、検証含め解いてみたいと思います。 問題内容解いた問題はReal or Not? NLP with Disaster Tweets(https:&#x2F;&#x2F;www.kaggle.com&#x2F;c&#x2F;nlp-getting-started ) です。ツイート内容からを本物の災害かどうか">
<meta property="og:type" content="article">
<meta property="og:title" content="Real or Not? NLP with Disaster Tweets を解く">
<meta property="og:url" content="http://gojtieji.com/2020/03/15/kagglenl/index.html">
<meta property="og:site_name" content="gojiteji&#39;s Blog">
<meta property="og:description" content="前回、NNで翻訳を作ってみたのですが、モデルの評価等をすっ飛ばしてきました。そこで、今回はkaggleで現在開いているNLPの問題を、検証含め解いてみたいと思います。 問題内容解いた問題はReal or Not? NLP with Disaster Tweets(https:&#x2F;&#x2F;www.kaggle.com&#x2F;c&#x2F;nlp-getting-started ) です。ツイート内容からを本物の災害かどうか">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="https://blog.gojiteji.com/images/kagglenl/hist.png">
<meta property="og:image" content="https://blog.gojiteji.com/images/kagglenl/loss.png">
<meta property="og:image" content="https://blog.gojiteji.com/images/kagglenl/acc.png">
<meta property="article:published_time" content="2020-03-15T13:47:44.000Z">
<meta property="article:modified_time" content="2022-04-22T22:49:23.183Z">
<meta property="article:author" content="gojiteji">
<meta property="article:tag" content="kaggle">
<meta property="article:tag" content="ML">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://blog.gojiteji.com/images/kagglenl/hist.png">
  
  
    <link rel="shortcut icon" href="/favicon/favicon.ico">
  
  
    
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/typeface-source-code-pro@0.0.71/index.min.css">

  
  
<link rel="stylesheet" href="/css/style.css">

  
    
<link rel="stylesheet" href="/fancybox/jquery.fancybox.min.css">

  
<meta name="generator" content="Hexo 6.1.0"></head>

<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="banner"></div>
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">gojiteji&#39;s Blog</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="main-nav">
        <a id="main-nav-toggle" class="nav-icon"></a>
        
          <a class="main-nav-link" href="/">Home</a>
        
          <a class="main-nav-link" href="/archives">Archives</a>
        
      </nav>
      <nav id="sub-nav">
        
        <a id="nav-search-btn" class="nav-icon" title="Search"></a>
      </nav>
      <div id="search-form-wrap">
        <form action="//google.com/search" method="get" accept-charset="UTF-8" class="search-form"><input type="search" name="q" class="search-form-input" placeholder="Search"><button type="submit" class="search-form-submit">&#xF002;</button><input type="hidden" name="sitesearch" value="http://gojtieji.com"></form>
      </div>
    </div>
  </div>
</header>

      <div class="outer">
        <section id="main"><article id="post-kagglenl" class="h-entry article article-type-post" itemprop="blogPost" itemscope itemtype="https://schema.org/BlogPosting">
  <div class="article-meta">
    <a href="/2020/03/15/kagglenl/" class="article-date">
  <time class="dt-published" datetime="2020-03-15T13:47:44.000Z" itemprop="datePublished">2020-03-15</time>
</a>
    
  </div>
  <div class="article-inner">
    
    
      <header class="article-header">
        
  
    <h1 class="p-name article-title" itemprop="headline name">
      Real or Not? NLP with Disaster Tweets を解く
    </h1>
  

      </header>
    
    <div class="e-content article-entry" itemprop="articleBody">
      
        <p>前回、NNで翻訳を作ってみたのですが、モデルの評価等をすっ飛ばしてきました。そこで、今回はkaggleで現在開いているNLPの問題を、検証含め解いてみたいと思います。</p>
<h2 id="問題内容"><a href="#問題内容" class="headerlink" title="問題内容"></a>問題内容</h2><p>解いた問題はReal or Not? NLP with Disaster Tweets(<a target="_blank" rel="noopener" href="https://www.kaggle.com/c/nlp-getting-started">https://www.kaggle.com/c/nlp-getting-started</a> ) です。ツイート内容からを本物の災害かどうかを2値推定するというものです。精度を上げれば、どんな災害がいつどこで起きているかをツイッターの呟きから特定する、ソーシャルセンサーとして活用できる気もします。<br>先に結果を書いておくと、スコアは0.74539でした。</p>
<span id="more"></span>
<h2 id="実装"><a href="#実装" class="headerlink" title="実装"></a>実装</h2><p>モデルの概要図は下の通りです。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">  text</span><br><span class="line">   ↓</span><br><span class="line">embedding</span><br><span class="line">   ↓</span><br><span class="line">Positional Embedding</span><br><span class="line">   ↓</span><br><span class="line">Encoder Layers</span><br><span class="line">   ↓</span><br><span class="line"> linear ← embedding ← keyword</span><br><span class="line">   ↓</span><br><span class="line">Sigmoid</span><br><span class="line">   ↓</span><br><span class="line">  出力</span><br></pre></td></tr></table></figure>
<p>前回同様,attentionベースで作成しました。ただ、翻訳ではないので、使用した注意機構はself-attentionのみとなります。</p>
<h3 id="全体概要"><a href="#全体概要" class="headerlink" title="全体概要"></a>全体概要</h3><p>コードは ( <a target="_blank" rel="noopener" href="https://github.com/gojiteji/kaggleNL">https://github.com/gojiteji/kaggleNL</a> ) にあげてるので、必要な部分を順を追って解説していきます。</p>
<h3 id="データ作成部分"><a href="#データ作成部分" class="headerlink" title="データ作成部分"></a>データ作成部分</h3><p>まずは辞書クラスを作ります。decoder機能(id-&gt;word変換)は使用しませんが、デバッグなど確認用に、前回同様の実装を行います。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Vocabulary</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,disabletokenize=<span class="literal">False</span></span>):</span><br><span class="line">        self.w2i=&#123;&#125;</span><br><span class="line">        self.i2w=&#123;&#125;</span><br><span class="line">        self.oov_char=<span class="string">&#x27;&lt;unk&gt;&#x27;</span></span><br><span class="line">        self.pad=<span class="string">&#x27;&lt;pad&gt;&#x27;</span></span><br><span class="line">        self.bos=<span class="string">&#x27;&lt;bos&gt;&#x27;</span></span><br><span class="line">        self.eos=<span class="string">&#x27;&lt;eos&gt;&#x27;</span></span><br><span class="line"></span><br><span class="line">        self.special_chars = [self.pad,self.oov_char,self.bos,self.eos]</span><br><span class="line">        self.data = <span class="string">&quot;&quot;</span></span><br><span class="line">        self._words=<span class="built_in">set</span>()</span><br><span class="line">        self.tokenize=disabletokenize</span><br><span class="line">        self.tknzr = TweetTokenizer()</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">update</span>(<span class="params">self,text</span>):</span><br><span class="line">        <span class="keyword">if</span>(self.tokenize):</span><br><span class="line">            self._words.update(text)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            self.data=self.tknzr.tokenize(text)</span><br><span class="line">            <span class="comment">#self.data=word_tokenize(text)</span></span><br><span class="line">            self._words.update(self.data)</span><br><span class="line">        self.w2i = &#123;w: (i + <span class="built_in">len</span>(self.special_chars)) <span class="keyword">for</span> i, w <span class="keyword">in</span> <span class="built_in">enumerate</span>(self._words)&#125;</span><br><span class="line"></span><br><span class="line">        self.i2w = &#123;i: w <span class="keyword">for</span> w, i <span class="keyword">in</span> self.w2i.items()&#125;</span><br><span class="line">        self.w2i[<span class="string">&#x27;&lt;pad&gt;&#x27;</span>] = <span class="number">0</span></span><br><span class="line">        self.i2w[<span class="number">0</span>] = <span class="string">&#x27;&lt;pad&gt;&#x27;</span></span><br><span class="line">        self.w2i[<span class="string">&#x27;&lt;unk&gt;&#x27;</span>] = <span class="number">1</span></span><br><span class="line">        self.i2w[<span class="number">1</span>] = <span class="string">&#x27;&lt;unk&gt;&#x27;</span></span><br><span class="line">        self.w2i[<span class="string">&#x27;&lt;bos&gt;&#x27;</span>] = <span class="number">2</span></span><br><span class="line">        self.i2w[<span class="number">2</span>] = <span class="string">&#x27;&lt;bos&gt;&#x27;</span></span><br><span class="line">        self.w2i[<span class="string">&#x27;&lt;eos&gt;&#x27;</span>] = <span class="number">3</span></span><br><span class="line">        self.i2w[<span class="number">3</span>] = <span class="string">&#x27;&lt;eos&gt;&#x27;</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">encode</span>(<span class="params">self,words</span>):</span><br><span class="line">        output=[]</span><br><span class="line">        <span class="keyword">if</span>(self.tokenize):</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment">#words=word_tokenize(words)</span></span><br><span class="line">            words=self.tknzr.tokenize(words)</span><br><span class="line">        <span class="keyword">for</span> word <span class="keyword">in</span> words:</span><br><span class="line">            <span class="comment">#辞書になし</span></span><br><span class="line">            <span class="keyword">if</span> word <span class="keyword">not</span> <span class="keyword">in</span> self.w2i:</span><br><span class="line">                index = self.w2i[self.oov_char]<span class="comment">#既存の&lt;unk&gt;を返す</span></span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment">#辞書にあり</span></span><br><span class="line">                index = self.w2i[word]<span class="comment">#idを引っ張ってくる</span></span><br><span class="line">            output.append(index)</span><br><span class="line">        <span class="keyword">return</span> output</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">decode</span>(<span class="params">self,indexes</span>):<span class="comment">#使いどころないけど確認用</span></span><br><span class="line">        out=[]</span><br><span class="line">        <span class="keyword">for</span> index <span class="keyword">in</span> indexes:</span><br><span class="line">            out.append(self.i2w[index])</span><br><span class="line">        <span class="keyword">return</span> out</span><br></pre></td></tr></table></figure>

<p>trainデータを形態素に分解して単語を記録します。分解方法は<a target="_blank" rel="noopener" href="https://www.nltk.org/">Natural Language Toolkit</a>のtweet tokenizerを使用しました。ハッシュタグやリプライ、顔文字も認識して分解してくれます。(最初は一般的な形態素解析ツールで分解していたため、これらが過度に分解されてしまい、文字が増えてしまいました)</p>
<p>次に、train,testデータをそれぞれ登録済みの単語でid化していきます。未登録の単語はid&#x3D;1を振ります。今回は、学習データとしてtextとkeyを用いました。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">keyword_voc.update(<span class="built_in">list</span>(keywords))</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> t <span class="keyword">in</span> raw_X_train:</span><br><span class="line">    text_voc.update(t[<span class="number">0</span>])</span><br><span class="line">maxlen=<span class="number">158</span></span><br></pre></td></tr></table></figure>

<h3 id="モデル設計部分"><a href="#モデル設計部分" class="headerlink" title="モデル設計部分"></a>モデル設計部分</h3><p>エンコードした文章をattentionし、その出力にkeyを結合してFFを通す事で出力を得ます。attention内部の、構造については、前回の翻訳と同様です。ただ、最初にも書いた通り、翻訳対象がないため、self-attentionのみを行っています。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">AttentionNN</span>(nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;&quot; 略 &quot;&quot;&quot;</span><span class="string">&quot;</span></span><br><span class="line"><span class="string">    def forward(self,source, key):</span></span><br><span class="line"><span class="string">        key=self.embedding_key(key)</span></span><br><span class="line"><span class="string">        mask_source = self.sequence_mask(source)</span></span><br><span class="line"><span class="string">        hs = self.Attantions(source, mask=mask_source)</span></span><br><span class="line"><span class="string">        a_out=hs.reshape(len(source),self.d_model*maxlen)#attention層出力</span></span><br><span class="line"><span class="string">        b_out =key</span></span><br><span class="line"><span class="string">        out = torch.cat([a_out,b_out],dim=1)#keywordを結合</span></span><br><span class="line"><span class="string">        out = self.linear_out(out)</span></span><br><span class="line"><span class="string">        out = self.activation_out(out)</span></span><br><span class="line"><span class="string">        return out</span></span><br></pre></td></tr></table></figure>

<h3 id="学習部分"><a href="#学習部分" class="headerlink" title="学習部分"></a>学習部分</h3><p>下画像のように、学習データが少しtarget&#x3D;0の方が多いため、ダウンサンプリングします。<br><img src="https://blog.gojiteji.com/images/kagglenl/hist.png" alt="trainデータの分布"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">X_train, y_train = rus.fit_sample(raw_X_train.reshape(-<span class="number">1</span>, <span class="number">2</span>) ,raw_y_train.reshape(-<span class="number">1</span>, <span class="number">1</span>) )</span><br></pre></td></tr></table></figure>

<p>また、test時に1&#x2F;4程度、新規の単語が増えるため、エポックごとに25% ランダな位置に&lt;unk&gt; 記号を含ませるようにしています。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">unks=<span class="number">0</span><span class="comment">#unkの量</span></span><br><span class="line">max_unks=(x_train.size - <span class="built_in">sum</span>(<span class="built_in">sum</span>(x_train==<span class="number">0</span>)))*<span class="number">0.25</span><span class="comment">#0以外の量</span></span><br><span class="line">max_row=x_train.shape[<span class="number">0</span>]</span><br><span class="line">max_colum=x_train.shape[<span class="number">1</span>]</span><br><span class="line">unks=[]</span><br><span class="line"><span class="keyword">while</span>(<span class="built_in">len</span>(unks)&lt;max_unks):</span><br><span class="line">    row=<span class="built_in">int</span>(np.random.rand()*max_row)</span><br><span class="line">    colum=<span class="built_in">int</span>(np.random.rand()*max_colum)</span><br><span class="line">    <span class="keyword">if</span>(<span class="keyword">not</span>(x_train[row,colum] == <span class="number">0</span>)):<span class="comment">#paddingじゃない</span></span><br><span class="line">        <span class="keyword">if</span>(<span class="keyword">not</span>(x_train[row,colum] == <span class="number">2</span>)):<span class="comment">#bosじゃない</span></span><br><span class="line">            <span class="keyword">if</span>(<span class="keyword">not</span>(x_train[row,colum] == <span class="number">3</span>)):<span class="comment">#eosじゃない</span></span><br><span class="line">                <span class="keyword">if</span>(<span class="keyword">not</span>(  [row,colum] <span class="keyword">in</span> unks)):<span class="comment">#既に置き換えていなければ</span></span><br><span class="line">                    x_train[row,colum]=<span class="number">1</span></span><br><span class="line">                    unks.append([row,colum])</span><br></pre></td></tr></table></figure>
<p>その他、学習部分に特別なものはありません。</p>
<h2 id="結果"><a href="#結果" class="headerlink" title="結果"></a>結果</h2><p>trainファイルの一部を検証に用いると、以下のような結果になりました。<br><img src="https://blog.gojiteji.com/images/kagglenl/loss.png" alt="損失関数の推移"><br><img src="https://blog.gojiteji.com/images/kagglenl/acc.png" alt="エポックに対する正答率の推移"></p>
<p>今回、各パラメータを</p>
<ul>
<li>エンコーダレイヤ数＝20</li>
<li>attentionヘッド数&#x3D;6</li>
<li>text埋め込み次元&#x3D;180</li>
<li>key埋め込み次元&#x3D;224</li>
<li>FFの次元&#x3D;190</li>
<li>学習率&#x3D;0.00001<br>と設定し、20エポックほど回しました。<br>提出結果、スコアは0.74539でした。まだまだ上がいるので、精進が必要そうです…</li>
</ul>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://gojtieji.com/2020/03/15/kagglenl/" data-id="cl2b44bai000su5p8bygcbz3b" data-title="Real or Not? NLP with Disaster Tweets を解く" class="article-share-link">Share</a>
      
      
      
  <ul class="article-tag-list" itemprop="keywords"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/ML/" rel="tag">ML</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/kaggle/" rel="tag">kaggle</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2020/03/22/kagglenl2/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          (改)Real or Not? NLP with Disaster Tweets を解く
        
      </div>
    </a>
  
  
    <a href="/2020/02/28/ja2th/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">タイに来たので、タイ語翻訳アプリを作った</div>
    </a>
  
</nav>

  
</article>


</section>
        
          <aside id="sidebar">
  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Tag Cloud</h3>
    <div class="widget tagcloud">
      <a href="/tags/AR/" style="font-size: 10px;">AR</a> <a href="/tags/Bluetooth/" style="font-size: 12px;">Bluetooth</a> <a href="/tags/CDN/" style="font-size: 10px;">CDN</a> <a href="/tags/CloudFront/" style="font-size: 10px;">CloudFront</a> <a href="/tags/GCF/" style="font-size: 10px;">GCF</a> <a href="/tags/GCP/" style="font-size: 10px;">GCP</a> <a href="/tags/GCS/" style="font-size: 10px;">GCS</a> <a href="/tags/GPS/" style="font-size: 10px;">GPS</a> <a href="/tags/GPT/" style="font-size: 10px;">GPT</a> <a href="/tags/Game/" style="font-size: 12px;">Game</a> <a href="/tags/Go/" style="font-size: 10px;">Go</a> <a href="/tags/IoT/" style="font-size: 12px;">IoT</a> <a href="/tags/ML/" style="font-size: 20px;">ML</a> <a href="/tags/NLP/" style="font-size: 16px;">NLP</a> <a href="/tags/S3/" style="font-size: 10px;">S3</a> <a href="/tags/TPU/" style="font-size: 10px;">TPU</a> <a href="/tags/Unity/" style="font-size: 10px;">Unity</a> <a href="/tags/Web/" style="font-size: 16px;">Web</a> <a href="/tags/aws/" style="font-size: 10px;">aws</a> <a href="/tags/hackathon/" style="font-size: 18px;">hackathon</a> <a href="/tags/heroku/" style="font-size: 10px;">heroku</a> <a href="/tags/internship/" style="font-size: 14px;">internship</a> <a href="/tags/kaggle/" style="font-size: 16px;">kaggle</a> <a href="/tags/others/" style="font-size: 12px;">others</a> <a href="/tags/poem/" style="font-size: 12px;">poem</a> <a href="/tags/%E5%82%99%E5%BF%98%E9%8C%B2/" style="font-size: 12px;">備忘録</a>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Recent Posts</h3>
    <div class="widget">
      <ul>
        
          <li>
            <a href="/2021/12/01/7816825e-f7e4-0e24-6448-9ec513e5e027/">AIは新入生になりきれるか?</a>
          </li>
        
          <li>
            <a href="/2021/11/22/jphacks2021-ad/">JPHACKS2021 Award Dayに参加しました!</a>
          </li>
        
          <li>
            <a href="/2021/11/01/jphacks2021/">JPHACKS2021に参加しました!</a>
          </li>
        
          <li>
            <a href="/2021/05/09/heroku/">Heroku(Python・Nodejs)開発中の備忘録</a>
          </li>
        
          <li>
            <a href="/2021/03/14/growthtech/">ABEMA Growth Techに参加しました。</a>
          </li>
        
      </ul>
    </div>
  </div>

  
    
  <div class="widget-wrap">
    <h3 class="widget-title">Archives</h3>
    <div class="widget">
      <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2021/">2021</a></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2020/">2020</a></li></ul>
    </div>
  </div>


  
</aside>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      
      &copy; 2022 gojiteji<br>
      Powered by <a href="https://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>

    </div>
    <nav id="mobile-nav">
  
    <a href="/" class="mobile-nav-link">Home</a>
  
    <a href="/archives" class="mobile-nav-link">Archives</a>
  
</nav>
    


<script src="/js/jquery-3.4.1.min.js"></script>



  
<script src="/fancybox/jquery.fancybox.min.js"></script>




<script src="/js/script.js"></script>





  </div>
</body>
</html>