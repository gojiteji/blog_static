<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> タイに来たので、タイ語翻訳アプリを作った · gojiteji's Blog</title><meta name="description" content="タイに来たので、タイ語翻訳アプリを作った - gojiteji"><title>gojiteji's Blog</title><meta name="description" content="gojiteji's Blog"><meta name="twitter:title" content="gojiteji's Blog"><meta name="twitter:description" content="gojiteji's Blog"><meta name="og:title" content="gojiteji's Blog"><meta name="og:description" content="gojiteji's Blog"><meta name="twitter:card" content="summary"><meta name="og:image"><meta name="twitter:image"><meta name="twitter:site" content="@gojiteji"><meta name="twitter:creator" content="@gojiteji"><meta name="og:site_name" content="gojiteji's Blog"><meta name="og:type" content="article"><meta name="og:url" content="https://blog.gojtieji.com/2020/02/28/ja2th/"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="https://blog.gojtieji.com/atom.xml" title="gojiteji's Blog"><meta name="generator" content="Hexo 6.1.0"><link rel="alternate" href="/atom.xml" title="gojiteji's Blog" type="application/atom+xml">
</head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/logo.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://gojiteji.com" target="_blank" class="nav-list-link">ABOUT</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">タイに来たので、タイ語翻訳アプリを作った</h1><div class="post-info">Feb 28, 2020</div><div class="post-content"><p><img src="https://blog.gojiteji.com/images/ja2th/title.png" alt="猫。タイで撮影。"></p>
<h2 id="はじめに"><a href="#はじめに" class="headerlink" title="はじめに"></a>はじめに</h2><p>昨年辺りから、流行りに乗って(?)機械学習を勉強していたのですが、「機械学習と実装がいイマイチ自分の中でつながらないなぁ」とずっと思っていました。<br>そんな中、訳あってタイに行く予定ができました。せっかくなので、現地で使う翻訳機を機械学習で自分で作って、「機械学習を機能として実装する」ことを経験してみたいと思い、今回挑戦してみました。</p>
<span id="more"></span>
<h2 id="目標"><a href="#目標" class="headerlink" title="目標"></a>目標</h2><p>日本語→タイ語の変換を、翻訳コーパスから機械学習により実装し、iOSアプリで実際に使える形にする。<strong>完成させる</strong>。</p>
<p>ちなみに、私のタイ語に関する事前知識は「文字を見たらタイ文字か否か判別できるけど、それ以上は全く読めない」程度です。</p>
<h2 id="結果"><a href="#結果" class="headerlink" title="結果"></a>結果</h2><p>iOSアプリを起点とした、翻訳は作成できました。<br><img src="https://blog.gojiteji.com/images/ja2th/sample.gif" ></img><br>学習文章を一部変えたものは、うまく翻訳できています。従って、使用コーパス(実装で説明)内の単純な文法は学習できていたようです。一方、長文になったり、複雑な文法になると実用するには厳しい出来具合となりました。<br>(以下の画像はGoolge翻訳で翻訳結果を確認しているため、文法などが正しいか、そもそもGoogle翻訳の結果が正しいかなどは不明です。)<br><img src="https://blog.gojiteji.com/images/ja2th/result0.png"><br><img src="https://blog.gojiteji.com/images/ja2th/result1.png"></p>
<p>間違った例は右から、「秋の季節ははっきりしています。」「冬はとても新しいです。」「軽いバス停まで歩いてください。」と翻訳された。</p>
<h2 id="実装概要"><a href="#実装概要" class="headerlink" title="実装概要"></a>実装概要</h2><p>実装は以下の通りです。実装にかかった期間は2.5~3.5日程度です。</p>
<ol>
<li>Google Colaboratory上でモデルを設計</li>
<li>GCPにモデルを移行し、APIサーバを構築</li>
<li>iOSアプリでをサーバと連携</li>
</ol>
<p>アーキテクチャ図は以下の通り。<br><img src="https://blog.gojiteji.com/images/ja2th/plan.png"><br>実際の運用は2と3のみ使用します。<br>ソースコードは<a target="_blank" rel="noopener" href="https://github.com/gojiteji/ja2th">githubに公開</a>しています。</p>
<h3 id="1-Google-Colaboratory上でモデルを設計"><a href="#1-Google-Colaboratory上でモデルを設計" class="headerlink" title="1.Google Colaboratory上でモデルを設計"></a>1.Google Colaboratory上でモデルを設計</h3><h4 id="コーパスを探す"><a href="#コーパスを探す" class="headerlink" title="コーパスを探す"></a>コーパスを探す</h4><p>まず、これがなければ実装の元も子もありません。今回用いたのは、TUFS Asian Language Parallel Corpus(<a target="_blank" rel="noopener" href="https://github.com/matbahasa/TALPCo">https://github.com/matbahasa/TALPCo</a> ) です。タイ語意外にも、複数のアジア圏の対訳コーパスが用意されています。さらにありがたいことに、Token化済みのデータも用意されています。</p>
<h4 id="Transformerによる翻訳"><a href="#Transformerによる翻訳" class="headerlink" title="Transformerによる翻訳"></a>Transformerによる翻訳</h4><p>翻訳はTransformerというモデルをベースに行いました。<br>自分の理解で簡単に説明すると、従来の翻訳で用いられていたRNNなどの再帰計算層がなく、代わりにAttention(入力に対して注目部分を特徴づける)や、Positional Embedding(データの位置関係埋め込み)で、翻訳を実現しているものです。間違っていたらすいません。</p>
<p>Transformerの論文の理解は、Ryobotさんの<a target="_blank" rel="noopener" href="http://deeplearning.hatenablog.com/entry/transformer">論文解説 Attention Is All You Need (Transformer)</a> を読むと、とてもわかりやすいです。</p>
<p>Transformerの実装に関しては、<a target="_blank" rel="noopener" href="https://www.amazon.co.jp/%E8%A9%B3%E8%A7%A3%E3%83%87%E3%82%A3%E3%83%BC%E3%83%97%E3%83%A9%E3%83%BC%E3%83%8B%E3%83%B3%E3%82%B0-TensorFlow-Keras-PyTorch%E3%81%AB%E3%82%88%E3%82%8B%E6%99%82%E7%B3%BB%E5%88%97%E3%83%87%E3%83%BC%E3%82%BF%E5%87%A6%E7%90%86-Compass-Books%E3%82%B7%E3%83%AA%E3%83%BC%E3%82%BA/dp/4839969515/ref=dp_ob_title_bk">詳解ディープラーニング 第2版 ~TensorFlow&#x2F;Keras・PyTorchによる時系列データ処理~</a>を参考にしました。</p>
<p>自分含め、「そもそもAttention？なんじゃそれ?」って思った人は、ソニー株式会社小林さんの説明する動画がアニメーション付きで理解しやすいです。</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/g5DSLeJozdw?start=606" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>


<h4 id="Transformerの実装"><a href="#Transformerの実装" class="headerlink" title="Transformerの実装"></a>Transformerの実装</h4><p>Pytorchで実装しました(<a target="_blank" rel="noopener" href="https://github.com/gojiteji/ja2th/blob/master/modeldesigning/ja2.ipynb">ソースコード</a>)。(先ほどの本を参考にした部分が多いです)<br>コードが長いので、流れを簡単に内容を書くと、</p>
<ul>
<li>学習時<ol>
<li>入力データ埋め込み→Positional Embedding→エンコーダ層(Self-Attention→Feed Forward)</li>
<li>教師データ埋め込み→Positional Embedding→デコーダ層(Self-Attention→Feed Forward→Source-Target-Attantion(ここでエンコーダの出力を入力)→Feed Forward)</li>
</ol>
</li>
<li>検証時<br>入力データ埋め込み→エンコーダ層→デコーダ層→出力をさらにデコーダ層→…として行き、順々にワードを生成</li>
</ul>
<p>と言う過程を経るものです。<br>この流れは、<a target="_blank" rel="noopener" href="https://arxiv.org/abs/1706.03762">Attention is all you need論文にある図1</a>そのものです。</p>
<p>パラメータはいくつか試した上で、</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">エンコーダ,デコーダの層数:7</span><br><span class="line">Multi headattentionでの接続数:4</span><br><span class="line">中間層の次元:20</span><br><span class="line">フィードフォワード層の次元:16</span><br></pre></td></tr></table></figure>
<p>と設定しています。</p>
<p>エポック数は200程度回しました。Colabの関係上、90分ごとにランタイムが切れるため、その度にモデルを保存して学習しています。コード上のepcoh数が少ないのはそのためです。</p>
<h3 id="2-GCPにモデルを移行し、APIサーバを構築"><a href="#2-GCPにモデルを移行し、APIサーバを構築" class="headerlink" title="2. GCPにモデルを移行し、APIサーバを構築"></a>2. GCPにモデルを移行し、APIサーバを構築</h3><h4 id="翻訳をGCP上のサーバーに移す"><a href="#翻訳をGCP上のサーバーに移す" class="headerlink" title="翻訳をGCP上のサーバーに移す"></a>翻訳をGCP上のサーバーに移す</h4><p>Google Colaboratory上で学習したモデルのパラメータを保存し、</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">model = Transformer(...).to(device)</span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">学習</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">&quot;&quot;&quot;</span></span><br><span class="line">torch.save(model.state_dict(), <span class="string">&#x27;保存ファイル名&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p>その後、サーバー上に同様のモデルのインスタンスを作成し、読み込むだけ。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">model = Transformer(...).to(device)<span class="comment">#インスタンス作成</span></span><br><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span> <span class="keyword">if</span> torch.cuda.is_available() <span class="keyword">else</span> <span class="string">&#x27;cpu&#x27;</span>)</span><br><span class="line">model.load_state_dict(torch.load(<span class="string">&#x27;保存ファイル名&#x27;</span>,map_location=device))</span><br></pre></td></tr></table></figure>

<p>上記プログラム中の<code>map_location=device</code>で、cpu&#x2F;gpuの切り替えも行ってくれるようです。このへん詰まるかと思っていましたが、すんなりcpu上で動いたので驚きました。</p>
<h4 id="辞書を引き継ぐ"><a href="#辞書を引き継ぐ" class="headerlink" title="辞書を引き継ぐ"></a>辞書を引き継ぐ</h4><p>入力されたTokengは、全てVocabularyインスタンスにより保存していますが、生成ごとに内部の辞書の順番が変わるため、Google Colaboratoryで学習に使用した辞書をそのままGCP上のサーバーに引き継ぐ必要があります。<br>これに関してはVocabularyインスタンスをごっそりpandasでpickleファイルとして保存し、サーバー側で読み込んで使用しています。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">ja_vocabulary=pd.read_pickle(<span class="string">&quot;ja.pkl&quot;</span>) </span><br><span class="line">th_vocabulary=pd.read_pickle(<span class="string">&quot;th.pkl&quot;</span>) </span><br></pre></td></tr></table></figure>

<h4 id="リクエストに対して翻訳結果を返答する"><a href="#リクエストに対して翻訳結果を返答する" class="headerlink" title="リクエストに対して翻訳結果を返答する"></a>リクエストに対して翻訳結果を返答する</h4><p>FlaskでPOSTが来たときに翻訳を実行するようにしました。<code>translate_from_japanese()</code>は入力のToken化、出力をBOS~EOS間で区切るための関数です。学習データの文章は既ににToken化されていましたが、生成時の入力文章はToken化されていないため、変換する必要があります。Token化には<a target="_blank" rel="noopener" href="https://github.com/taishi-i/nagisa">nagisa</a>を使用しました。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">translate_from_japanese</span>(<span class="params">text</span>):</span><br><span class="line">    <span class="keyword">if</span>(text <span class="keyword">is</span> <span class="literal">None</span>):</span><br><span class="line">        <span class="keyword">return</span> <span class="string">&quot;入力されていません&quot;</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        preds = model(torch.LongTensor([ja_vocabulary.encode(nagisa.tagging(text).words)]))</span><br><span class="line">        _out = preds.view(-<span class="number">1</span>).tolist()</span><br><span class="line">        out = <span class="string">&#x27; &#x27;</span>.join(th_vocabulary.decode(_out))</span><br><span class="line">        begin = out.find(<span class="string">&#x27;&lt;s&gt;&#x27;</span>)</span><br><span class="line">        end= out.find(<span class="string">&#x27;&lt;/s&gt;&#x27;</span>)</span><br><span class="line">        <span class="keyword">return</span> out[begin+<span class="number">3</span>:end]</span><br><span class="line"></span><br><span class="line"><span class="meta">@app.route(<span class="params"><span class="string">&#x27;/ja2th&#x27;</span>,methods=[<span class="string">&#x27;POST&#x27;</span>]</span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ja2th</span>():</span><br><span class="line">    <span class="keyword">if</span> request.method == <span class="string">&#x27;POST&#x27;</span>:</span><br><span class="line">        text = request.get_data()</span><br><span class="line">    text=translate_from_japanese(text)</span><br><span class="line">    <span class="keyword">return</span> text</span><br></pre></td></tr></table></figure>

<h3 id="3-iOSアプリでをサーバと連携"><a href="#3-iOSアプリでをサーバと連携" class="headerlink" title="3. iOSアプリでをサーバと連携"></a>3. iOSアプリでをサーバと連携</h3><p>iOSアプリは<a target="_blank" rel="noopener" href="https://github.com/gojiteji/ja2th/blob/master/iOS%20app/Translate/%E4%BF%BA%E4%BF%BATranslate/ViewController.swift">コードを見てわかるように</a>、特に小難しいことはしておしません。POSTの送信とその返答結果の表示を、ボタンを押すことで実行。また、それっぽいアイコンを設定しているだけです。Xcodeで実装しています。<br><img src="https://blog.gojiteji.com/images/ja2th/app.png"><br>リクエスト時のサーバー出力</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">[<span class="string">&#x27;&lt;unk&gt;&#x27;</span>, <span class="string">&#x27;&lt;unk&gt;&#x27;</span>, <span class="string">&#x27;&lt;unk&gt;&#x27;</span>, <span class="string">&#x27;&lt;unk&gt;&#x27;</span>, <span class="string">&#x27;&lt;unk&gt;&#x27;</span>, <span class="string">&#x27;&lt;unk&gt;&#x27;</span>, <span class="string">&#x27;山田&#x27;</span>, <span class="string">&#x27;さん&#x27;</span>, <span class="string">&#x27;は&#x27;</span>, <span class="string">&#x27;どこ&#x27;</span>, <span class="string">&#x27;に&#x27;</span>, <span class="string">&#x27;い&#x27;</span>, <span class="string">&#x27;ます&#x27;</span>, <span class="string">&#x27;か&#x27;</span>, <span class="string">&#x27;&lt;unk&gt;&#x27;</span>, <span class="string">&#x27;&lt;unk&gt;&#x27;</span>]</span><br><span class="line">[<span class="string">&#x27;山田&#x27;</span>, <span class="string">&#x27;さん&#x27;</span>, <span class="string">&#x27;は&#x27;</span>, <span class="string">&#x27;どこ&#x27;</span>, <span class="string">&#x27;に&#x27;</span>, <span class="string">&#x27;い&#x27;</span>, <span class="string">&#x27;ます&#x27;</span>, <span class="string">&#x27;か&#x27;</span>]</span><br><span class="line">&lt;s&gt; คุณ ยามาดะ อยู่ ที่ ไหน ครับ &lt;/s&gt; ครับ &lt;/s&gt; ค่ะ &lt;/s&gt; อัน ไหน ครับ &lt;/s&gt; เป็น อยู่ ห้อง ไหน ครับ</span><br></pre></td></tr></table></figure>
<h2 id="終わりに"><a href="#終わりに" class="headerlink" title="終わりに"></a>終わりに</h2><p>今回はとりあえず完成させることをにしていたため、いくつかステップを飛ばしている部分があります。本システムはコーパスさえあれば他の言語にも転用可能なシステムのため、また、国外にいく機会があれば検証などをしっかり行いながら改良していきたいと思います。</p>
<p>個人的な感想として、Transformerの概要を読んだだけではよくわからなかった、実際に学習させるとどのような特徴を捉えるのかなどを見れたことがよかったです。<br>(時間的制約の上に、タイ語が全然読めないため、出力の正しさの判断がぱっと見じゃ全然わからなかったことがとても大変でした..)</p>
</div></article></div></main><footer><div class="paginator"><a href="/2020/03/15/kagglenl/" class="prev">PREV</a><a href="/2020/01/21/donotcallmeturkycnn/" class="next">NEXT</a></div><div class="copyright"><p>© 2020 - 2022 <a href="https://blog.gojtieji.com">gojiteji</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>