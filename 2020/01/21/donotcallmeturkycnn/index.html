<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Don't call me turkryをcnnでとく · gojiteji's Blog</title><meta name="description" content="Don't call me turkryをcnnでとく - gojiteji"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="https://blog.gojtieji.com/atom.xml" title="gojiteji's Blog"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="gojiteji's Blog" type="application/atom+xml">
</head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/logo.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://gojiteji.com" target="_blank" class="nav-list-link">ABOUT</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">Don't call me turkryをcnnでとく</h1><div class="tags"><a href="/tags/kaggle/" class="tag-title">#kaggle</a><a href="/tags/ML/" class="tag-title">#ML</a></div><div class="post-info">Jan 21, 2020</div><div class="post-content"><p>ネットサーフィン中に面白そうなものを見つけたので、後出しになるが解いてみる。🦃<br><a target="_blank" rel="noopener" href="https://www.kaggle.com/c/dont-call-me-turkey/">https://www.kaggle.com/c/dont-call-me-turkey/</a></p>
<span id="more"></span>
<h2 id="学習データ"><a href="#学習データ" class="headerlink" title="学習データ"></a>学習データ</h2><p>学習データは１データごとに下のような構造</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">- audio_embedding</span><br><span class="line">    - 0</span><br><span class="line">      ・</span><br><span class="line">      ・</span><br><span class="line">      ・</span><br><span class="line">    - 9</span><br><span class="line">- is_turkey</span><br><span class="line">- vid_id</span><br><span class="line">- end_time_seconds_youtube_clip</span><br><span class="line">- start_time_seconds_youtube_clip</span><br></pre></td></tr></table></figure>

<p><strong>audio_embedding</strong>とは、<a target="_blank" rel="noopener" href="https://github.com/tensorflow/models/tree/master/research/audioset/vggish">VGGish</a>によって、YouTubeの動画データをを1秒ごとに128次元に圧縮したものらしい。これが最大10秒分ある。</p>
<p><strong>vid</strong>はYouTubeで動画を開いたときにurlの末尾につく、<strong>youtube.com&#x2F;watch?v&#x3D;2lAe1cqCOXo</strong>の<strong>2lAe1cqCOXo</strong>の値のよう。試しに<strong>is_turkey&#x3D;1</strong>の動画を見ると、七面鳥の鳴き声を確認できる。</p>
<h2 id="モデル設計"><a href="#モデル設計" class="headerlink" title="モデル設計"></a>モデル設計</h2><ul>
<li><p>データ前処理<br>  10秒に満たないデータがあるため、0で埋める。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line">train = pd.read_json(<span class="string">&#x27;train.json&#x27;</span>)</span><br><span class="line">test = pd.read_json(<span class="string">&#x27;test.json&#x27;</span>)</span><br><span class="line"><span class="comment">#train data</span></span><br><span class="line">train_x_raw=np.array(train.audio_embedding)<span class="comment">#    [1195,10,128]たまに足りなくておかしい</span></span><br><span class="line">train_x =np.zeros((<span class="number">1195</span>,<span class="number">10</span>,<span class="number">128</span>))</span><br><span class="line"><span class="comment">##整形</span></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(train_x_raw)):</span><br><span class="line">    <span class="keyword">if</span>(np.array(train_x_raw[i]).shape[<span class="number">0</span>] <span class="keyword">is</span> <span class="keyword">not</span> <span class="number">10</span>):<span class="comment">#足りない場合埋める</span></span><br><span class="line">        lack=<span class="number">10</span> - np.array(train_x_raw[i]).shape[<span class="number">0</span>]</span><br><span class="line">            train_x[i]=np.append(train_x_raw[i],np.zeros((lack,<span class="number">128</span>)    ),axis=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">else</span>:<span class="comment">#足りてたらnumpyに変換</span></span><br><span class="line">        train_x[i]=np.array(train_x_raw[i])</span><br><span class="line">train_y=train.is_turkey</span><br><span class="line"></span><br><span class="line"><span class="comment">#test data</span></span><br><span class="line">test_x_raw=test.audio_embedding<span class="comment">#[1196,10,128]</span></span><br><span class="line">test_x =np.zeros((<span class="number">1196</span>,<span class="number">10</span>,<span class="number">128</span>))</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(test_x_raw)):</span><br><span class="line">    <span class="keyword">if</span>(np.array(test_x_raw[i]).shape[<span class="number">0</span>] <span class="keyword">is</span> <span class="keyword">not</span> <span class="number">10</span>):<span class="comment">#足りない場合埋める</span></span><br><span class="line">        lack=<span class="number">10</span> - np.array(test_x_raw[i]).shape[<span class="number">0</span>]</span><br><span class="line">        test_x[i]=np.append(test_x_raw[i],np.zeros((lack,<span class="number">128</span>)),ax    <span class="keyword">is</span>=<span class="number">0</span>)</span><br><span class="line">    <span class="keyword">else</span>:<span class="comment">#足りてたらnumpyに変換</span></span><br><span class="line">        test_x[i]=np.array(test_x_raw[i])</span><br></pre></td></tr></table></figure>
</li>
<li><p>モデル定義<br>  10x128を1枚の画像のようにcnnの入力とする。損失関数<code>nn.BCEWithLogitsLoss()</code>はsigmoidを含むため、モデルの出力は(0~1)でない。</p>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">ML</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, device=<span class="string">&#x27;cuda&#x27;</span></span>):</span><br><span class="line">        <span class="built_in">super</span>().__init__()</span><br><span class="line">        self.device = device</span><br><span class="line">        self.pad = nn.ZeroPad2d(<span class="number">1</span>)</span><br><span class="line">        self.conv1 = nn.Conv2d(<span class="number">1</span>, <span class="number">64</span>,(<span class="number">2</span>,<span class="number">12</span>))</span><br><span class="line">        self.pool1 = nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.conv2 = nn.Conv2d(<span class="number">64</span>, <span class="number">64</span>, (<span class="number">2</span>,<span class="number">2</span>))</span><br><span class="line">        self.pool2 = nn.MaxPool2d(<span class="number">2</span>)</span><br><span class="line">        self.dropout = nn.Dropout(p=<span class="number">0.3</span>)</span><br><span class="line">        self.f1=nn.ReLU()</span><br><span class="line">        self.f2=nn.ReLU()</span><br><span class="line">        self.l = nn.Linear(<span class="number">5760</span>,<span class="number">1</span>)</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self,x</span>):</span><br><span class="line">        h=self.conv1(h)</span><br><span class="line">        h=self.f1(h)</span><br><span class="line">        h=self.dropout(h)</span><br><span class="line">        h=self.pool1(h)</span><br><span class="line">        h=self.conv2(h)</span><br><span class="line">        h=self.f2(h)</span><br><span class="line">        h=self.dropout(h)</span><br><span class="line">        h=self.pool2(h)</span><br><span class="line">    </span><br><span class="line">        h=h.reshape(<span class="number">5760</span>)</span><br><span class="line">        h=self.l(h)<span class="comment">#出力形式に線形変換</span></span><br><span class="line">        h=self.dropout(h)</span><br><span class="line">        <span class="keyword">return</span> h</span><br></pre></td></tr></table></figure>

<ul>
<li><p>学習部分</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">device = torch.device(<span class="string">&#x27;cuda&#x27;</span>)</span><br><span class="line">model = cnn(device=device).to(device)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">criterion = nn.BCEWithLogitsLoss()</span><br><span class="line">optimizer = optimizers.Adam(model.parameters())</span><br><span class="line"><span class="keyword">def</span> <span class="title function_">train_step</span>(<span class="params">x,t</span>):</span><br><span class="line">    model.train()</span><br><span class="line">    y=model(x)</span><br><span class="line">    loss = criterion(y,t)</span><br><span class="line">    optimizer.zero_grad()</span><br><span class="line">    loss.backward()</span><br><span class="line">    optimizer.step()</span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="comment">#パラメータ更新開始</span></span><br><span class="line">epochs =<span class="number">100</span></span><br><span class="line">lists=np.array(<span class="built_in">range</span>(<span class="built_in">len</span>(train_x)))</span><br><span class="line">histories=np.array([])</span><br><span class="line"><span class="keyword">for</span> epoch <span class="keyword">in</span> tqdm(<span class="built_in">range</span>(epochs)):</span><br><span class="line">    train_loss = <span class="number">0.</span></span><br><span class="line">    np.random.shuffle(lists)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> lists:</span><br><span class="line">        x_tmp = np.array(train_x[i]).reshape(<span class="number">1</span>,<span class="number">1</span>,<span class="number">10</span>,<span class="number">128</span>)</span><br><span class="line">        x = torch.from_numpy(x_tmp).<span class="built_in">type</span>(<span class="string">&#x27;torch.FloatTensor&#x27;</span>).to(<span class="string">&#x27;cuda&#x27;</span>)<span class="comment">#入力形式に変換(入力)</span></span><br><span class="line">        t = torch.from_numpy(np.array([train_y[i]])).<span class="built_in">type</span>(<span class="string">&#x27;torch.Floa    tTensor&#x27;</span>).to(<span class="string">&#x27;cuda&#x27;</span>)<span class="comment">#入力形式に変換(出力)</span></span><br><span class="line">        loss = train_step(x,t)<span class="comment">#順伝播,逆伝播,更新</span></span><br><span class="line">        train_loss += loss.item()</span><br><span class="line">    train_loss /= <span class="built_in">len</span>(train_x)</span><br><span class="line">    histories=np.append(histories,train_loss)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;Epoch: &#123;&#125;, Cost:     &#123;:.3f&#125;&#x27;</span>.<span class="built_in">format</span>(epoch+<span class="number">1</span>,train_loss))</span><br></pre></td></tr></table></figure>
</li>
<li><p>損失関数の推移</p>
</li>
</ul>
<p><img src="https://i.imgur.com/s2nTjiu.png"></p>
<ul>
<li>結果<br>  実際のcompetitionの様子を見てるとまだまだ上がいるので、改良の余地がありそう。<br><img src="https://i.imgur.com/VMfY5QI.png"></li>
</ul>
<h2 id="出典・参考："><a href="#出典・参考：" class="headerlink" title="出典・参考："></a>出典・参考：</h2><ul>
<li><p>Don’t call me turkey! kaggle<br><a target="_blank" rel="noopener" href="https://www.kaggle.com/c/dont-call-me-turkey/">https://www.kaggle.com/c/dont-call-me-turkey/</a></p>
</li>
<li><p>(PyTorch) Temporal Convolutional Networks<br><a target="_blank" rel="noopener" href="https://www.kaggle.com/ceshine/pytorch-temporal-convolutional-networks">https://www.kaggle.com/ceshine/pytorch-temporal-convolutional-networks</a></p>
</li>
<li><p>VGGish <a target="_blank" rel="noopener" href="https://github.com/tensorflow/models/tree/master/research/audioset/vggish">https://github.com/tensorflow/models/tree/master/research/audioset/vggish</a></p>
</li>
</ul>
</div></article></div></main><footer><div class="paginator"><a href="/2020/02/28/ja2th/" class="prev">PREV</a><a href="/2020/01/21/%E3%83%96%E3%83%AD%E3%82%B0%E5%A7%8B%E3%82%81%E3%81%BE%E3%81%99%E3%80%82/" class="next">NEXT</a></div><div class="copyright"><p>© 2020 - 2022 <a href="https://blog.gojtieji.com">gojiteji</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>