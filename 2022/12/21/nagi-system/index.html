<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> NAGIシステムの概要 · gojiteji's Blog</title><meta name="description" content="NAGIシステムの概要 - gojiteji"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/favicon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="https://blog.gojtieji.com/atom.xml" title="gojiteji's Blog"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 6.3.0"><link rel="alternate" href="/atom.xml" title="gojiteji's Blog" type="application/atom+xml">
</head><body><div class="wrap"><header><a href="/" class="logo-link"><img src="/logo.png" alt="logo"></a><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">BLOG</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="https://gojiteji.com" target="_blank" class="nav-list-link">ABOUT</a></li></ul></header><main class="container"><div class="post"><article class="post-block"><h1 class="post-title">NAGIシステムの概要</h1><div class="tags"><a href="/tags/NLP/" class="tag-title">#NLP</a><a href="/tags/AI/" class="tag-title">#AI</a></div><div class="post-info">Dec 21, 2022</div><div class="post-content"><p><strong>これは<a target="_blank" rel="noopener" href="https://qiita.com/advent-calendar/2022/naist">NAISTアドベントカレンダー2022</a> 21日目の投稿です。</strong></p>
<p>先日HuggingFace Spacesにて，3つのAIによる決議システム「<a target="_blank" rel="noopener" href="https://huggingface.co/spaces/gojiteji/NAGISystem">NAGI System</a>」を公開しました．その仕組みを簡単に紹介します．</p>
<span id="more"></span>
<h2 id="仕組み"><a href="#仕組み" class="headerlink" title="仕組み"></a>仕組み</h2><p>promptという手法を使っています．近年の機械学習モデルを特定のタスクに当てるとなると，1. 事前学習と2. fine-tuningの二つのステップが必要です．一方で，promptというのは，1. は同じですが，その次にfine-tuningを行いません．じゃあどうしているかというと，事前学習のタスクに近い形でタスク情報を入力してやれば，fine-tuningせずとも，特定タスクを解く性能は持ってるよね，といった感じで解いています．<br>具体的には，次のようなタスクを解いています．</p>
<h2 id="BERTの場合"><a href="#BERTの場合" class="headerlink" title="BERTの場合"></a>BERTの場合</h2><p>BERTは事前学習で入力文章の<code>[MASK]</code>部分を埋めるタスクを解いています．<br>なので，promptでは2022&#x2F;12&#x2F;19時点で以下のような入力をBERTに与えています．</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&quot;MELCHIORは科学者としての人格を持っています。人間とMELCHIORの対話です。人間「&quot;</span>+sue+<span class="string">&quot;。承認 か 否定 のどちらかで答えてください。」&quot;</span>+<span class="string">&quot;MELCHIOR 「[MASK]」&quot;</span></span><br></pre></td></tr></table></figure>

<p><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/gojiteji/NAGISystem/blob/main/app.py#L18">ソースコード</a></p>
<h2 id="GPT2の場合"><a href="#GPT2の場合" class="headerlink" title="GPT2の場合"></a>GPT2の場合</h2><p>GPT2は事前学習で入力文章の次単語を予測するタスクを解いています．<br>なので，promptでは2022&#x2F;12&#x2F;19時点で以下のような入力をGPT2に与えています．</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;CASPERは女としての人格を持っています。人間とCASPERの対話です。人間「&#x27;</span>+sue+<span class="string">&#x27;。承認 か 否定 のどちらかで答えてください。」&#x27;</span>+<span class="string">&quot;CASPER 「&quot;</span></span><br></pre></td></tr></table></figure>
<p><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/gojiteji/NAGISystem/blob/main/app.py#L27">ソースコード</a></p>
<h2 id="mT5の場合可決割合の調節のためmBERTに変更"><a href="#mT5の場合可決割合の調節のためmBERTに変更" class="headerlink" title="mT5の場合可決割合の調節のためmBERTに変更"></a><del>mT5の場合</del>可決割合の調節のためmBERTに変更</h2><p><del>mT5は事前学習で<code>&lt;X&gt;</code>や<code>&lt;Y&gt;</code>でマスクされた文を予測するタスクを解いています．</del><br><del>なので，promptでは2022&#x2F;12&#x2F;19時点で以下のような入力をmT5に与えています．</del></p>
<p><del>‘BALTHASARは母としての人格としての人格を持っています。人間とBALTHASARの対話です。人間「’+sue+’。承認 か 否定 のどちらかで答えてください。」’+”BALTHASAR 「<X>」”</del></p>
<p><del><a target="_blank" rel="noopener" href="https://huggingface.co/spaces/gojiteji/NAGISystem/blob/main/app.py#L30">ソースコード</a></del></p>
<h2 id="出力に関して"><a href="#出力に関して" class="headerlink" title="出力に関して"></a>出力に関して</h2><p>もちろん，これらの回答が必ず「承認」か「否定」かになるわけではないです．そこで，「承認」のスコアと「否定」のスコアを比較して結果を出力しています．おそらくですが，「承認」と「否定」を事前学習で学習で対になるように学習できていないので，現状学習データに多く含まれていた「否定」が多く出る状況になっているのだと思います．</p>
<p>こういったことが簡単に実装できる，AIの民主化を大きく進めてくれたHuggingFace社には感謝しかないですね🤗</p>
<h2 id="終わりに"><a href="#終わりに" class="headerlink" title="終わりに"></a>終わりに</h2><p>近年のStable Diffusion関連の話題で聞いたことある単語が出てきたって人もいるのではないでしょうか．少しでもAI・機械学習分野の中身に興味を持っていただけたら幸いです！</p>
<h2 id="参考文献"><a href="#参考文献" class="headerlink" title="参考文献"></a>参考文献</h2><p>Pengfei Liu, Weizhe Yuan, Jinlan Fu, Zhengbao Jiang, Hiroaki Hayashi, and Graham Neubig. 2021. Pre-train, Prompt, and Predict: A Systematic Survey of Prompting Methods in Natural Language Processing.<br><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2107.13586">https://arxiv.org/abs/2107.13586</a></p>
</div></article></div></main><footer><div class="paginator"><a href="/2022/12/14/languagemodels/" class="next">NEXT</a></div><div class="copyright"><p>© 2020 - 2022 <a href="https://blog.gojtieji.com">gojiteji</a>, powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">hexo-theme-apollo</a>.</p></div></footer></div><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></body></html>